{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Analyze the dataset\n",
    "Parse the groundtruth information into a dictionary. The key will be the name of the picture and the value a list of the signals and their information. \n",
    "\n",
    "This data structure let us find directly the picture that we want to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Enable matplotline inline display\n",
    "%matplotlib inline\n",
    "\n",
    "# Import built-in modules\n",
    "import os\n",
    "\n",
    "# Import third party modules\n",
    "import imageio\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import local functions\n",
    "from utils import get_files_from_dir, get_gt_data, get_img, get_n_samples_of_col, \\\n",
    "    get_unique_values_of_col, get_patch, gt_to_img, gt_to_mask, parse_gt_data, ROOT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Useful directories\n",
    "TRAIN_DIR = os.path.join(ROOT_DIR, 'dataset', 'train')\n",
    "TRAIN_GTS_DIR = os.path.join(TRAIN_DIR, 'gt')\n",
    "TRAIN_MASKS_DIR = os.path.join(TRAIN_DIR, 'mask')\n",
    "TEST_DIR = os.path.join(ROOT_DIR, 'dataset', 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gt_filenames = get_files_from_dir(TRAIN_GTS_DIR)\n",
    "mask_filenames = get_files_from_dir(TRAIN_MASKS_DIR)\n",
    "\n",
    "data = dict()\n",
    "\n",
    "for gt in gt_filenames:\n",
    "    mask_path = gt_to_mask(gt)\n",
    "    mask_img = get_img(TRAIN_MASKS_DIR, mask_path)\n",
    "    \n",
    "    lines = get_gt_data(TRAIN_GTS_DIR, gt)\n",
    "        \n",
    "    im_name = gt_to_mask(gt)\n",
    "    im_open = get_img(TRAIN_MASKS_DIR, im_name)\n",
    "\n",
    "    lista = list()\n",
    "    for l in lines:\n",
    "        tly, tlx, bry, brx, tipo = parse_gt_data(l)\n",
    "\n",
    "        d = dict()\n",
    "        d['type'] = tipo.strip()\n",
    "        \n",
    "        w = brx - tlx\n",
    "        h = bry - tly\n",
    "        \n",
    "        d['width'] = w\n",
    "        d['height'] = h\n",
    "        d['bbox_area'] = w*h\n",
    "        d['form_factor'] = w/h\n",
    "        \n",
    "        d['tly'] = round(tly)\n",
    "        d['tlx'] = round(tlx)\n",
    "        d['bry'] = round(bry)\n",
    "        d['brx'] = round(brx)\n",
    "        \n",
    "        mask_patch = get_patch(mask_img, d['tlx'], d['tly'], d['brx'], d['bry'])\n",
    "        mask_area = np.count_nonzero(mask_patch)\n",
    "        d['mask_area'] = mask_area\n",
    "        d['filling_ratio'] = mask_area / d['bbox_area']\n",
    "        d['mask'] = mask_patch != 0\n",
    "        \n",
    "        lista.append(d)\n",
    "        \n",
    "    data[gt] = lista\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show information in pandas format to filter the signals by type easily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'type', 'width', 'height', 'form_factor', 'tlx', 'tly', 'brx', 'bry', \n",
    "    'bbox_area', 'mask_area', 'filling_ratio', 'mask'\n",
    "]\n",
    "df = pd.DataFrame.from_dict({(i,n): data[i][n]\n",
    "                        for i in data.keys()\n",
    "                        for n,v in enumerate(data[i])}, columns=columns, orient='index').sort_values(['type'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_counts = df.groupby('type').aggregate(np.std).round(2)\n",
    "#type_counts = df.groupby('type').aggregate(np.median)\n",
    "#type_counts = df.groupby('type').aggregate(np.average)\n",
    "#type_counts = df.groupby('type').aggregate(np.std)\n",
    "\n",
    "\n",
    "cmap = mpl.colors.ListedColormap(['red','red','red', 'blue', 'purple', 'blue'])\n",
    "type_counts['mask_area'].plot(figsize=(12, 8),kind='pie',sort_columns=True, colormap=cmap, title=\"Number of pixels per class\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions: \n",
    "Large range of sizes: \n",
    "- From 900 pixels (about 30x30) to 56000 of area\n",
    "\n",
    "\n",
    "Total number of pixels of each class is very different:\n",
    "- class F: 42%\n",
    "- class B: 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Study average, std and median values\n",
    "type_counts = df.groupby('type').aggregate(np.average).round(2)\n",
    "print(\"Average values\")\n",
    "print(type_counts)\n",
    "type_counts.drop(columns=['width', 'height', 'form_factor'])\\\n",
    "    .plot(figsize=(5, 8), kind='bar', sort_columns=True,subplots=True)\n",
    "type_counts['filling_ratio'].plot(figsize=(7, 3),kind='bar',sort_columns=True, title=\"Average filling ratio\")\n",
    "\n",
    "type_counts = df.groupby('type').aggregate(np.std).round(3)\n",
    "print(\"\\n\\nStandard deviation values\")\n",
    "print(type_counts)\n",
    "\n",
    "type_counts = df.groupby('type').aggregate(np.median).round(2)\n",
    "print(\"\\n\\nMedian values\")\n",
    "print(type_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "Average and median bounding-box sizes around 90 pixels\n",
    "\n",
    "Filling_ratio pretty consistent through classes\n",
    "- Triangles: 0.5\n",
    "- Circles: 0.77\n",
    "- Rectangles: 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Split training dataset\n",
    "\n",
    "Extract the 30% of the training images of each class to set up a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose randomly the 70% of each class\n",
    "# Count number of signals per class\n",
    "signal_types = get_unique_values_of_col(df, 'type')\n",
    "n_signals = df['type'].value_counts(sort=False).reindex(signal_types)\n",
    "print(n_signals)\n",
    "n_signals = df['type'].value_counts(sort=False).reindex(signal_types).aggregate(sum)\n",
    "print(\"\\n\\nNumber of signals: {}\".format(n_signals))\n",
    "\n",
    "# Plot\n",
    "df['type']\\\n",
    "    .value_counts(sort=False)\\\n",
    "    .reindex(signal_types)\\\n",
    "    .plot(figsize=(10, 7),kind='bar',sort_columns=True, title=\"Number of images per class\", grid=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small captions of each type\n",
    "plt.figure(figsize=(20, 20))\n",
    "n_img = 5\n",
    "types = get_unique_values_of_col(df, 'type')\n",
    "l_types = len(types)\n",
    "\n",
    "for t_idx, t in enumerate(types):\n",
    "    samples_gt = get_n_samples_of_col(df, 'type', n_img, t)\n",
    "    for gt_idx, gt in enumerate(samples_gt):\n",
    "        train_name = gt_to_img(gt)\n",
    "\n",
    "        row = df.loc[gt]\n",
    "        row_data = row[row['type'] == t].iloc[0]\n",
    "\n",
    "        img = get_img(TRAIN_DIR, train_name)\n",
    "        img_patch = get_patch(img, row_data['tlx'], row_data['tly'], row_data['brx'], row_data['bry'])\n",
    "\n",
    "        plt.subplot(l_types, n_img, gt_idx + 1 + t_idx*n_img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title('{type}: {filename}'.format(type=t, filename=train_name))\n",
    "        plt.imshow(img_patch * row_data['mask'][..., np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only one class\n",
    "df_filtered = df[df['type'] == \"B\"].drop(columns='mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_train = df_filtered.sample(frac=0.3)\n",
    "print(df_sorted_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(zip(df_sorted_train.index.get_level_values(0).tolist(),df_sorted_train.index.get_level_values(1).tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_test = pd.concat([df_filtered, df_sorted_train]).drop_duplicates(keep=False)\n",
    "print(df_sorted_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will obtain different list:\n",
    "- train_images_red: Train selection of red signals\n",
    "- train_images_blue: Train selection of blue signals\n",
    "- train_images_mix: Train selection of red/blue signals\n",
    "- train_images: Total train selection\n",
    "- val_images: Total validation selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to do all the process in one cell\n",
    "def split_class(signal_class, train_percentage):\n",
    "    \n",
    "    # Choose one signal class\n",
    "    df_filtered = df[df['type'] == signal_class].drop(columns=['mask'])\n",
    "    \n",
    "    # Sample randomly the percentage choosen\n",
    "    df_sorted_train = df_filtered.sample(frac=train_percentage)\n",
    "    \n",
    "    # Save train selection\n",
    "    train_images = tuple(zip(df_sorted_train.index.get_level_values(0).tolist(),df_sorted_train.index.get_level_values(1).tolist()))\n",
    "    \n",
    "    # Delete train selection to get validation selection\n",
    "    df_sorted_test = pd.concat([df_filtered,df_sorted_train]).drop_duplicates(keep=False)\n",
    "    val_images = tuple(zip(df_sorted_test.index.get_level_values(0).tolist(),df_sorted_test.index.get_level_values(1).tolist()))\n",
    "    \n",
    "    return train_images, val_images\n",
    "\n",
    "def split_dataset(data,percentage, classes):\n",
    "    \n",
    "    train_images = []\n",
    "    val_images = []\n",
    "    \n",
    "    for signal_class in classes:\n",
    "        temp_train_images, temp_val_images = split_class(signal_class, percentage)\n",
    "        train_images += temp_train_images\n",
    "        val_images += temp_val_images\n",
    "    return train_images, val_images\n",
    "\n",
    "\n",
    "classes_red = ['A','B','C']\n",
    "classes_blue = ['D','F']\n",
    "classes_mix = ['E']\n",
    "\n",
    "train_images_red, val_images_red = split_dataset(data, 0.7, classes_red)\n",
    "train_images_blue, val_images_blue = split_dataset(data, 0.7, classes_blue)\n",
    "train_images_mix, val_images_mix = split_dataset(data, 0.7, classes_mix)\n",
    "\n",
    "train_images = train_images_red + train_images_blue + train_images_mix\n",
    "val_images = val_images_red + val_images_blue + val_images_mix\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Separation by colour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For each color group of images (_Red, Blue, Mix_) we calculate the histograms in different color spaces.\n",
    "The goal is to build a color mask applying the propper thresholds. We will obtain this information from the histograms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "from skimage import exposure\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "dirs_jpg = get_files_from_dir(TRAIN_DIR)\n",
    "\n",
    "##############################\n",
    "# Calculate color histograms:\n",
    "##############################\n",
    "\n",
    "def color_histogram(gt_dictionary, train_selec, path_jpg, color_space):\n",
    "    \n",
    "    '''gt_dictionary = Dictionary containing ground truth data\n",
    "       train selec = Group of training images divided by color (Red, Blue, Mix)\n",
    "       path_jpg = Path to training images \n",
    "       color_space = Color space in which to perform histogram (rgb, hsv, ycbcr, xyz)'''\n",
    "\n",
    "    c0_hist = np.zeros(255)\n",
    "    c1_hist = np.zeros(255)\n",
    "    c2_hist = np.zeros(255)\n",
    "\n",
    "    r_hist = np.zeros(255)\n",
    "    g_hist = np.zeros(255)\n",
    "    b_hist = np.zeros(255)\n",
    "\n",
    "    for gt, position in train_selec:\n",
    "        v = gt_dictionary[gt][position]\n",
    "\n",
    "        jpg_name = gt.replace('gt.', '').replace('txt', 'jpg')\n",
    "        mask_name = gt.replace('gt', 'mask').replace('txt', 'png')\n",
    "\n",
    "        jpg_roi = imageio.imread(os.path.join(path_jpg, jpg_name))[v['tly']:v['bry'], v['tlx']:v['brx']]\n",
    "        mask_roi = imageio.imread(os.path.join(TRAIN_MASKS_DIR, mask_name))[v['tly']:v['bry'], v['tlx']:v['brx']]\n",
    "\n",
    "        if color_space=='rgb':\n",
    "            final_roi = jpg_roi\n",
    "            r0 = 0\n",
    "            rf = 255\n",
    "\n",
    "        elif color_space=='hsv':\n",
    "            final_roi = color.rgb2hsv(jpg_roi) \n",
    "            r0 = 0\n",
    "            rf = 1\n",
    "\n",
    "        elif color_space=='ycbcr':\n",
    "            final_roi = color.rgb2ycbcr(jpg_roi)\n",
    "            r0 = 0\n",
    "            rf = 255\n",
    "\n",
    "        elif color_space=='xyz':\n",
    "            final_roi = color.rgb2xyz(jpg_roi)\n",
    "            r0 = 0\n",
    "            rf = 1\n",
    "\n",
    "        mask_roi[mask_roi==0] = 0\n",
    "        mask_roi[mask_roi!=0] = 1\n",
    "\n",
    "        bins = np.histogram(final_roi[:,:,0] * mask_roi, bins=255, range=(r0,rf))[1]\n",
    "        c0_hist += np.histogram(final_roi[:,:,0] * mask_roi, bins=255, range=(r0,rf))[0]\n",
    "        c1_hist += np.histogram(final_roi[:,:,1] * mask_roi, bins=255, range=(r0,rf))[0]\n",
    "        c2_hist += np.histogram(final_roi[:,:,2] * mask_roi, bins=255, range=(r0,rf))[0]\n",
    "\n",
    "    return bins, c0_hist, c1_hist, c2_hist, r0, rf\n",
    "\n",
    "def hsv_histogram(gt_dictionary, path_jpg):\n",
    "\n",
    "    h_hist = np.zeros(255)\n",
    "    s_hist = np.zeros(255)\n",
    "    v_hist = np.zeros(255)\n",
    "\n",
    "    for gt, values in list(gt_dictionary.items()):\n",
    "        for v in values:\n",
    "\n",
    "            jpg_name = gt.replace('gt.', '').replace('txt', 'jpg')\n",
    "            jpg_roi = imageio.imread(os.path.join(path_jpg, jpg_name))[v['tly']:v['bry'], v['tlx']:v['brx']]\n",
    "            hsv_roi = color.rgb2hsv(jpg_roi)*255\n",
    "            \n",
    "            bins = np.histogram(hsv_roi[:,:,0], bins=255, range=(1,255))[1]\n",
    "            h_hist += np.histogram(hsv_roi[:,:,0], bins=255, range=(1,255))[0]\n",
    "            s_hist += np.histogram(hsv_roi[:,:,1], bins=255, range=(1,255))[0]\n",
    "            v_hist += np.histogram(hsv_roi[:,:,2], bins=255, range=(1,255))[0]\n",
    "    \n",
    "    return bins, h_hist, s_hist, v_hist\n",
    "\n",
    "######################################\n",
    "# Calculate RGB normalized histogram:\n",
    "######################################\n",
    "\n",
    "def norm_histogram(gt_dictionary, train_selec, path_jpg):\n",
    "\n",
    "    '''gt_dictionary = Dictionary containing ground truth data\n",
    "       train selec = Group of training images divided by color (Red, Blue, Mix)\n",
    "       path_jpg = Path to training images'''\n",
    "\n",
    "    c0_hist = np.zeros(255)\n",
    "    c1_hist = np.zeros(255)\n",
    "    c2_hist = np.zeros(255)\n",
    "    \n",
    "    for gt, position in train_selec:\n",
    "        v = gt_dictionary[gt][position]\n",
    "\n",
    "        jpg_name = gt.replace('gt.', '').replace('txt', 'jpg')\n",
    "        mask_name = gt.replace('gt', 'mask').replace('txt', 'png')\n",
    "\n",
    "        # Important: in order to normalize we need to read THE FULL IMAGE. If we normalize the rois, \n",
    "        # we will be training our algorithm poorly.After trying this, we saw all images have saturated\n",
    "        # pixels (aka normalized image = original image). \n",
    "\n",
    "        # We will normalize the ROIs, knowing this is poorly training the algorithm.\n",
    "\n",
    "        jpg_roi = imageio.imread(os.path.join(path_jpg, jpg_name))[v['tly']:v['bry'], v['tlx']:v['brx']]\n",
    "        mask_roi = imageio.imread(os.path.join(TRAIN_MASKS_DIR, mask_name))[v['tly']:v['bry'], v['tlx']:v['brx']]\n",
    "\n",
    "        jpg_max_0 = np.max(jpg_roi[:,:,0])\n",
    "        jpg_max_1 = np.max(jpg_roi[:,:,1])\n",
    "        jpg_max_2 = np.max(jpg_roi[:,:,2])\n",
    "\n",
    "        final_roi = jpg_roi\n",
    "        jpg_max_0, jpg_max_1, jpg_max_2 = jpg_max_0, jpg_max_1, jpg_max_2 \n",
    "\n",
    "        mask_roi[mask_roi==0] = 0\n",
    "        mask_roi[mask_roi!=0] = 1\n",
    "\n",
    "        bins = np.histogram(final_roi[:,:,0] * mask_roi, bins=255, range=(0,1))[1]\n",
    "        c0_hist += np.histogram(final_roi[:,:,0] / jpg_max_0 * mask_roi, bins=255, range=(0,1))[0]\n",
    "        c1_hist += np.histogram(final_roi[:,:,1] / jpg_max_1 * mask_roi, bins=255, range=(0,1))[0]\n",
    "        c2_hist += np.histogram(final_roi[:,:,2] / jpg_max_2 * mask_roi, bins=255, range=(0,1))[0]\n",
    "\n",
    "    return bins, c0_hist, c1_hist, c2_hist\n",
    "\n",
    "\n",
    "###################\n",
    "# Plot histograms:\n",
    "###################\n",
    "\n",
    "def plot_histogram(hist0, hist1, hist2, r0, rf, color_name):\n",
    "    \n",
    "    '''hist0, hist1, hist2 = Histograms corresponding to channels 0, 1, 2 of the images\n",
    "       r0, r1 = Min and Max values of the selected color space\n",
    "       color_name = Name of the resulting plot'''\n",
    "    \n",
    "    path_figures = os.path.join('figures')\n",
    "    try:\n",
    "        os.stat(path_figures)\n",
    "    except:\n",
    "        os.mkdir(path_figures)\n",
    "\n",
    "    x = np.linspace(r0, rf, 255)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    \n",
    "    axs[0].bar(x[:-2], hist0[1:-1], color='r', width=0.8*(rf-r0)/255, label='Ch1')\n",
    "    axs[1].bar(x[:-2], hist1[1:-1], color='g', width=0.8*(rf-r0)/255, label='Ch2')\n",
    "    axs[2].bar(x[:-2], hist2[1:-1], color='b', width=0.8*(rf-r0)/255, label='Ch3')\n",
    "\n",
    "    axs[0].legend()\n",
    "    axs[1].legend()\n",
    "    axs[2].legend()\n",
    "\n",
    "    axs[0].set_xlabel('8bit quantification')\n",
    "    axs[1].set_xlabel('8bit quantification')\n",
    "    axs[2].set_xlabel('8bit quantification')\n",
    "    axs[0].set_ylabel('Total number of px')\n",
    "    \n",
    "    fig.suptitle(color_name + ' histogram')\n",
    "    plt.savefig('figures/' + str(color_name) + '_hist.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate histograms in different color spaces:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the signals by color and calculate the histogram of each group:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RGB histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, r_hist_red, g_hist_red, b_hist_red, rgb0, rgbf = color_histogram(data, train_images_red, TRAIN_DIR, 'rgb')\n",
    "bins, r_hist_blue, g_hist_blue, b_hist_blue, rgb0_blue, rgbf = color_histogram(data, train_images_blue, TRAIN_DIR, 'rgb')\n",
    "bins, r_hist_mix, g_hist_mix, b_hist_mix, rgb0, rgbf = color_histogram(data, train_images_mix, TRAIN_DIR, 'rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized RGB histograms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** in order to normalize we need to read THE FULL IMAGE. If we normalize the rois, \n",
    "we will be training our algorithm poorly. After trying this, we saw all images have saturated\n",
    "pixels (aka normalized image = original image). \n",
    "\n",
    "We will normalize the ROIs, knowing this is poorly training the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_norm, r_hist_norm_red, g_hist_norm_red, b_hist_norm_red = norm_histogram(data, train_images_red, TRAIN_DIR)\n",
    "bins_norm, r_hist_norm_blue, g_hist_norm_blue, b_hist_norm_blue = norm_histogram(data, train_images_blue, TRAIN_DIR)\n",
    "bins_norm, r_hist_norm_mix, g_hist_norm_mix, b_hist_norm_mix = norm_histogram(data, train_images_mix, TRAIN_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HSV histograms:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbins, h_hist_red, s_hist_red, v_hist_red, hsv0, hsvf = color_histogram(data, train_images_red, TRAIN_DIR, 'hsv')\n",
    "hbins, h_hist_blue, s_hist_blue, v_hist_blue, hsv0, hsvf = color_histogram(data, train_images_blue, TRAIN_DIR, 'hsv')\n",
    "hbins, h_hist_mix, s_hist_mix, v_hist_mix, hsv0, hsvf = color_histogram(data, train_images_mix, TRAIN_DIR, 'hsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yCbCr histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ybins, y_hist_red, cb_hist_red, cr_hist_red, ycbcr0, ycbcrf = color_histogram(data, train_images_red, TRAIN_DIR, 'ycbcr')\n",
    "ybins, y_hist_blue, cb_hist_blue, cr_hist_blue, ycbcr0, ycbcrf = color_histogram(data, train_images_blue, TRAIN_DIR, 'ycbcr')\n",
    "ybins, y_hist_mix, cb_hist_mix, cr_hist_mix, ycbcr0, ycbcrf = color_histogram(data, train_images_mix, TRAIN_DIR, 'ycbcr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XYZ histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbins, xx_hist_red, yy_hist_red, zz_hist_red, xyz0, xyzf = color_histogram(data, train_images_red, TRAIN_DIR, 'xyz')\n",
    "xbins, xx_hist_blue, yy_hist_blue, zz_hist_blue, xyz0, xyzf = color_histogram(data, train_images_blue, TRAIN_DIR, 'xyz')\n",
    "xbins, xx_hist_mix, yy_hist_mix, zz_hist_mix, xyz0, xyzf = color_histogram(data, train_images_mix, TRAIN_DIR, 'xyz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot histograms in different color spaces:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot RGB histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(r_hist_red, g_hist_red, b_hist_red, rgb0, rgbf, 'RGB - Red Signals')\n",
    "plot_histogram(r_hist_blue, g_hist_blue, b_hist_blue, rgb0, rgbf, 'RGB - Blue Signals')\n",
    "plot_histogram(r_hist_mix, g_hist_mix, b_hist_mix, rgb0, rgbf, 'RGB - Mixed Signals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot normalized RGB histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(r_hist_norm_red, g_hist_norm_red, b_hist_norm_red, rgb0, rgbf, 'RGB Norm - Red Signals')\n",
    "plot_histogram(r_hist_norm_blue, g_hist_norm_blue, b_hist_norm_blue, rgb0, rgbf, 'RGB Norm - Blue Signals')\n",
    "plot_histogram(r_hist_norm_mix, g_hist_norm_mix, b_hist_norm_mix, rgb0, rgbf, 'RGB Norm - Mixed Signals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot HSV histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(h_hist_red, s_hist_red, v_hist_red, hsv0, hsvf, 'HSV - Red signals')\n",
    "plot_histogram(h_hist_blue, s_hist_blue, v_hist_blue, hsv0, hsvf, 'HSV - Blue signals')\n",
    "plot_histogram(h_hist_mix, s_hist_mix, v_hist_mix, hsv0, hsvf, 'HSV - Mixed signals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot yCbCr histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(y_hist_red, cb_hist_red, cr_hist_red, ycbcr0, ycbcrf, 'yCbCr - Red signals')\n",
    "plot_histogram(y_hist_blue, cb_hist_blue, cr_hist_blue, ycbcr0, ycbcrf, 'yCbCr - Blue signals')\n",
    "plot_histogram(y_hist_mix, cb_hist_mix, cr_hist_mix, ycbcr0, ycbcrf, 'yCbCr - Mixed signals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot XYZ histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_histogram(xx_hist_red, yy_hist_red, zz_hist_red, xyz0, xyzf, 'XYZ - Red signals')\n",
    "plot_histogram(xx_hist_blue, yy_hist_blue, zz_hist_blue, xyz0, xyzf, 'XYZ - Blue signals')\n",
    "plot_histogram(xx_hist_mix, yy_hist_mix, zz_hist_mix, xyz0, xyzf, 'XYZ - Mixed signals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized RGB histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "\n",
    "dirs_jpg = get_files_from_dir(TRAIN_DIR)\n",
    "\n",
    "def norm_histogram(gt_dictionary, train_selec, path_jpg, color_space):\n",
    "\n",
    "    c0_hist = np.zeros(255)\n",
    "    c1_hist = np.zeros(255)\n",
    "    c2_hist = np.zeros(255)\n",
    "    \n",
    "    for gt, position in train_selec:\n",
    "        v = gt_dictionary[gt][position]\n",
    "\n",
    "        jpg_name = gt.replace('gt.', '').replace('txt', 'jpg')\n",
    "        mask_name = gt.replace('gt', 'mask').replace('txt', 'png')\n",
    "\n",
    "        # Important: in order to normalize we need to read THE FULL IMAGE. If we normalize the rois, \n",
    "        # we will be training our algorithm poorly.After trying this, we saw all images have saturated\n",
    "        # pixels (aka normalized image = original image). \n",
    "\n",
    "        # We will normalize the ROIs, knowing this is poorly training the algorithm.\n",
    "\n",
    "        jpg_roi = imageio.imread(os.path.join(path_jpg, jpg_name))[v['tly']:v['bry'], v['tlx']:v['brx']]\n",
    "        mask_roi = imageio.imread(os.path.join(TRAIN_MASKS_DIR, mask_name))[v['tly']:v['bry'], v['tlx']:v['brx']]\n",
    "\n",
    "        jpg_max_0 = np.max(jpg_roi[:,:,0])\n",
    "        jpg_max_1 = np.max(jpg_roi[:,:,1])\n",
    "        jpg_max_2 = np.max(jpg_roi[:,:,2])\n",
    "\n",
    "        if color_space=='rgb':\n",
    "            final_roi = jpg_roi\n",
    "            jpg_max_0, jpg_max_1, jpg_max_2 = jpg_max_0, jpg_max_1, jpg_max_2 \n",
    "\n",
    "        mask_roi[mask_roi==0] = 0\n",
    "        mask_roi[mask_roi!=0] = 1\n",
    "\n",
    "        bins = np.histogram(final_roi[:,:,0] * mask_roi, bins=255, range=(0,1))[1]\n",
    "        c0_hist += np.histogram(final_roi[:,:,0] / jpg_max_0 * mask_roi, bins=255, range=(0,1))[0]\n",
    "        c1_hist += np.histogram(final_roi[:,:,1] / jpg_max_1 * mask_roi, bins=255, range=(0,1))[0]\n",
    "        c2_hist += np.histogram(final_roi[:,:,2] / jpg_max_2 * mask_roi, bins=255, range=(0,1))[0]\n",
    "\n",
    "    return bins, c0_hist, c1_hist, c2_hist\n",
    "\n",
    "\n",
    "################################################\n",
    "# Calculate histograms with traffic signal data:\n",
    "################################################\n",
    "\n",
    "# RGB histograms:\n",
    "\n",
    "bins_norm, r_hist_norm, g_hist_norm, b_hist_norm = norm_histogram(data, train_images, TRAIN_DIR, 'rgb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot normalized histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_histogram(r_hist_norm, 0, 1, 'Red_norm', 'r')\n",
    "#plot_histogram(g_hist_norm, 0, 1, 'Green_norm', 'g')\n",
    "#plot_histogram(b_hist_norm, 0, 1, 'Blue_norm', 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparar las mÃ¡scaras obtenidas con el ground truth.\n",
    "\n",
    "Podemos ver si sirven las funciones que ya nos dieron hechas.\n",
    "\n",
    "\n",
    "\n",
    "## Conclusions: \n",
    "\n",
    "1. HSV & yCbCr are better than RGB or XYZ for color segmentation.\n",
    "\n",
    "2. Selected thresholds: \n",
    "    - RGB: Red: r > 0.03; 0.46 < r < 0.51; 0.98 < r\n",
    "    - RGB: Blue: 0.59 < b < 0.62\n",
    "    - yCbCr: Cb = 0.4 < cb < 0.65\n",
    "    - yCbCr: Cr = 0.38 < Cr < 0.7\n",
    "    \n",
    "3. We only study the colors of the signals, so we expect to have False Positives of the same colors in the background"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
